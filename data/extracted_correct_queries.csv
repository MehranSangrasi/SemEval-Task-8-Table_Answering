query
"df[(df['gender'] == 'M') & (df['age'] == df['age'].min())].shape[0] > 0"
"df.loc[df['rank'] == df['rank'].max(), 'title'].astype(str).replace('nan', '').iloc[0]"
"df.sort_values('age').head(4)['city'].astype(str).replace('nan', '').tolist()"
"df['country'].value_counts(ascending=True).head(2).index.tolist()"
"df.loc[df['gender'] == 'F'].nsmallest(4, 'rank')['rank'].tolist()"
"df[df['Survived'] == True]['Fare'].apply(lambda x: '0-50' if x <= 50 else '50-100' if x <= 100 else '100-150' if x <= 150 else '150+').value_counts().idxmax()"
"df[df['Survived'] == True]['Fare'].apply(lambda x: '0-50' if x <= 50 else '50-100' if x <= 100 else '100-150' if x <= 150 else '150+').value_counts(ascending=False).tail(3).index.tolist()"
"df[df['Survived'] == True]['Age'].apply(lambda x: '0-18' if x <= 18 else '18-30' if x <= 30 else '30-50' if x <= 50 else '50+').value_counts().head(4).index.tolist()"
"df[df['Survived'] == True]['Fare'].nlargest(4).tolist()"
"df.loc[df['How often do you wear glasses? ðŸ‘“'] == 'Constantly'].shape[0]"
"df['total_amount'].nlargest(5).tolist()"  
"(df['borough'].str.contains('Brooklyn', case=False, na=False)).any()"  
"df['agency'].astype(str).str.contains('OFFICE OF SPECIAL ENFORCEMENT', case=False, na=False).any()"  
"df[df['borough'].str.contains('Queens', case=False, na=False)].shape[0]" 
"sorted(df['descriptor'].value_counts(ascending=True).index[:2], reverse=True)"  
"df['hour'].value_counts().nsmallest(2).index.tolist()"  
"df['price'].astype(object).apply(lambda x: isinstance(x, str)).sum()"
"df['host_verifications'].explode().value_counts().idxmin()"  
"df['host_verifications'].explode().value_counts().head(2).index.tolist()"  
"((df['Height_ft<gx:number>'] > 6) & (df['Agility<gx:number>'] > 90)).any()"  
"df.groupby('Nationality<gx:category>')['Overall<gx:number>'].mean().nlargest(5).index.tolist()"
"df.groupby('Club<gx:category>')['Potential<gx:number>'].mean().nlargest(6).index.tolist()"
"(df['inj'] <= 500).all()"
"(df['len'] <= 100).all()"
"(df['fat'] <= 100).all()"
"(df['PRCP'] <= 5).all()"
"(df['SNWD'] <= 10).all()"
"df['Incident Description'].value_counts().nlargest(3).index.tolist()"

"df[df['Sex'] == 'M']['ChestPainType'].value_counts().nlargest(4).index.tolist()"
"df.loc[df['opening_date_clean'].isin(df['opening_date_clean'].nsmallest(1)), 'Status'].str.strip().str.lower().eq('operating').any()"
"df[df['year_introduced'] == df['year_introduced'].min()]['Type'].iloc[0]"
"df.sort_values('opening_date_clean').head(4)['coaster_name'].tolist()"
"df.sort_values('opening_date_clean').head(6)['year_introduced'].tolist()"
"df.loc[df['price'].idxmax(), 'room_type']"
"df.loc[df['accommodates'] == df['accommodates'].max(), 'host_acceptance_rate'].iloc[df.loc[df['accommodates'] == df['accommodates'].max(), 'host_acceptance_rate'].str.rstrip('%').astype(float).argmax()]"
"pd.to_numeric(df['host_response_rate'].str.rstrip('%'), errors='coerce').dropna().loc[lambda x: x > 0].nsmallest(2).apply(lambda x: f'{x}%').tolist()"
"pd.to_numeric(df['host_response_rate'].str.rstrip('%'), errors='coerce').dropna().nsmallest(2).apply(lambda x: f'{x}%').tolist()"
"pd.to_numeric(df['host_acceptance_rate'].str.rstrip('%'), errors='coerce').dropna().nlargest(4).apply(lambda x: f'{x}%').tolist()"
"df['Date Hired'].dt.year.eq(2019).any()"
"df['Date Hired'].dt.year.value_counts().idxmax()"
"df.loc[(df['Promoted in the last 5 years?'].str.strip().str.lower() == 'yes') & (df['Department'].notna()),'Department'].value_counts().head(3).index.tolist()"
"df['Date Hired'].dt.year.value_counts().head(3).index.tolist()"
"df.loc[df['Promoted in the last 5 years?'].astype(str).str.strip().str.lower() == 'yes', 'Average Monthly Hours'].dropna().nsmallest(5).tolist()"
"df['Aircaft_Damage_Type'].astype(str).str.lower().isin(['destroyed', 'damaged beyond repair']).any()"
"df['Ground_Casualties'].astype(str).str.strip().ne('0').any()"
"df['Onboard_Total'].str.extract(r'Occupants:\s*(\d+)')[0].astype(float).max()"
"df.loc[(df['Date'].dt.year == 2022) & (df['Date'].dt.month == 1)].shape[0]"
"df['Fatalities'].astype(str).str.strip().ne('0').sum()"
"df.loc[df['Fatalities'].idxmax(), 'Incident_Cause(es)']"
"df.loc[df['Onboard_Total'].str.extract(r'Occupants:\s*(\d+)')[0].astype(float).idxmax(), 'Incident_Location']"
"df['Incident_Location'].value_counts().sort_index().nlargest(5).index.tolist()"
"df['Onboard_Passengers'].str.extract(r'Occupants: (\d+)', expand=False).astype(float).nlargest(5).tolist()"
"df['Onboard_Crew'].str.extract(r'Occupants: (\d+)', expand=False).astype(float).nlargest(3).tolist()"
"df['Onboard_Total'].str.extract(r'Occupants: (\d+)', expand=False).astype(float).nlargest(4).tolist()"
"df['Ground_Casualties'].str.extract(r'Fatalities:\s*(\d+)', expand=False).astype(float).nlargest(6).tolist()"
"(df['PhoneService'].str.strip().eq('Yes')).all()"
"df['property_type'].value_counts().head(4).index.tolist()"
"df.loc[(df['season'] == 'Summer') & (df['tmin'] < 10)].shape[0] > 0"
"df.loc[df['season'] == 'Winter', 'tmin'].mean()"
"((df['SEXO'] == 'Female') & (df['NUTS1'] == 'ESTE')).any()"
"df[df['SEXO'] == 'Male']['RETRINOIN'].mean()"
"df['Ranking'].max()"
"df.groupby('URLs')['Avg. monthly searches'].mean().nlargest(3).index.tolist()"
"df[df['Ranking'] < 5]['Competition'].value_counts().tail(2).index.tolist()"
"df.sort_values(by='Ranking', ascending=False).head(4)['Keyword'].tolist()"
"df.sort_values(by='Ranking', ascending=True).head(3)['URLs'].tolist()"
"df[df['Keyword'] == 'no code data science']['Ranking'].nlargest(4).tolist()"
"df[df['Competition'] == 'Medium']['Avg. monthly searches'].nsmallest(3).tolist()"
"df[df['Competition'] == 'Low']['Ranking'].nlargest(5).tolist()"
"(df['Age'] > 60).any()"
"(df['DiabetesPedigreeFunction'] > 2.5).any()"
"(df['Insulin'].astype(int) > 150).sum()"
"df.loc[df['BMI'] > 0].nsmallest(2, 'BMI')['Outcome'].tolist()"
"df.nlargest(5, 'Insulin')['Outcome'].tolist()"
"df.nsmallest(4, 'BloodPressure')['Outcome'].tolist()"
"df.sort_values('Pregnancies', ascending=False).head(4)['Age'].tolist()"
"df.nsmallest(3, 'Glucose')['BMI'].tolist()"
"df.nlargest(5, 'DiabetesPedigreeFunction')['BloodPressure'].tolist()"
"(df['material_type'] == 'Op-Ed').any()"
"df['material_type'].nunique()"
"df['headline'].str.len().max()"
"df.loc[df['date'].astype(str).eq('2021-01-02 00:00:00+00:00')].shape[0]"

"df.loc[df['headline'].astype(str).str.len().eq(96),'material_type'].iloc[0]"
"df.loc[df['keywords'].apply(lambda x: len(x) if isinstance(x,list) else 0).idxmin(),'material_type']"

"df.loc[df['keywords'].apply(lambda x: len(x) if isinstance(x,list) else 0).sort_values().head(4).index, 'material_type'].tolist()"
"(df.loc[df['keywords'].apply(lambda x: len(x) if isinstance(x,list) else 0).sort_values().tail(4).index,'headline']).astype(str).str.len().tolist()"
"df['headline'].astype(str).str.len().nlargest(5).tolist()"
"df[df['In which country do you currently reside?'] == 'United Kingdom of Great Britain and Northern Ireland'].shape[0]"
"df['What programming languages do you use on a regular basis?'].apply(len).mode()[0]"
"df[df['Geographies'].apply(len) > 0]['Geographies'].explode().value_counts().head(4).index.tolist()"
"df[df['General Segments'].apply(len) > 0]['General Segments'].explode().value_counts().head(3).index.tolist()"
"df[df['What programming languages do you use on a regular basis?'].apply(len) > 0]['What programming languages do you use on a regular basis?'].explode().value_counts().head(6).index.tolist()"
"df['(Average) For how many years have you used machine learning methods?'].nlargest(3).tolist()"
"df[df['rating'] == df['rating'].min()]['Company'].iloc[0]"
"df[df['Company'] == 'Wise']['rating'].unique().tolist()[:4]"
"df[df['Company'] == 'N26']['rating'].unique().tolist()[:5]"
"df['Education'].mode()[0]"